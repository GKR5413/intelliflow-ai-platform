spring:
  application:
    name: analytics-service
  profiles:
    active: ${SPRING_PROFILES_ACTIVE:dev}
  
  datasource:
    url: jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:analytics_db}
    username: ${DB_USERNAME:postgres}
    password: ${DB_PASSWORD:postgres}
    driver-class-name: org.postgresql.Driver
  
  jpa:
    hibernate:
      ddl-auto: validate
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
    show-sql: ${SHOW_SQL:false}
  
  flyway:
    enabled: true
    locations: classpath:db/migration
    baseline-on-migrate: true
  
  data:
    mongodb:
      uri: mongodb://${MONGO_HOST:localhost}:${MONGO_PORT:27017}/${MONGO_DB:analytics}
      username: ${MONGO_USERNAME:}
      password: ${MONGO_PASSWORD:}
    redis:
      host: ${REDIS_HOST:localhost}
      port: ${REDIS_PORT:6379}
      password: ${REDIS_PASSWORD:}
      timeout: 2000ms
      lettuce:
        pool:
          max-active: 10
          max-idle: 10
          min-idle: 1
  
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      properties:
        spring.json.add.type.headers: false
    consumer:
      group-id: analytics-service-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring.json.trusted.packages: "*"

server:
  port: ${SERVER_PORT:8084}
  servlet:
    context-path: /api/v1

eureka:
  client:
    service-url:
      defaultZone: ${EUREKA_URL:http://localhost:8761/eureka}
    register-with-eureka: true
    fetch-registry: true
  instance:
    prefer-ip-address: true
    instance-id: ${spring.application.name}:${spring.application.instance_id:${random.value}}

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: always
  metrics:
    export:
      prometheus:
        enabled: true

logging:
  level:
    com.intelliflow: ${LOG_LEVEL:INFO}
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"

resilience4j:
  circuitbreaker:
    instances:
      default:
        slidingWindowSize: 10
        minimumNumberOfCalls: 5
        failureRateThreshold: 50
        waitDurationInOpenState: 30s
  retry:
    instances:
      default:
        maxAttempts: 3
        waitDuration: 1s

# Analytics specific configurations
analytics:
  batch-processing:
    enabled: true
    batch-size: 1000
    schedule: "0 0 */6 * * *" # Every 6 hours
  real-time:
    enabled: true
    window-size: 300 # 5 minutes
  reports:
    retention-days: 90
    export-formats: ["JSON", "CSV", "PDF"]
  aggregation:
    user-metrics: true
    transaction-metrics: true
    fraud-metrics: true
    system-metrics: true

---
spring:
  config:
    activate:
      on-profile: dev
  datasource:
    url: jdbc:postgresql://localhost:5432/analytics_db
  data:
    mongodb:
      uri: mongodb://localhost:27017/analytics
  jpa:
    show-sql: true

logging:
  level:
    root: INFO
    com.intelliflow: DEBUG

---
spring:
  config:
    activate:
      on-profile: prod
  datasource:
    url: jdbc:postgresql://${RDS_ENDPOINT}:5432/${RDS_DB_NAME}
    username: ${RDS_USERNAME}
    password: ${RDS_PASSWORD}
  data:
    mongodb:
      uri: mongodb://${DOCUMENTDB_ENDPOINT}:27017/${DOCUMENTDB_NAME}
      username: ${DOCUMENTDB_USERNAME}
      password: ${DOCUMENTDB_PASSWORD}
    redis:
      host: ${ELASTICACHE_ENDPOINT}
      port: 6379
  kafka:
    bootstrap-servers: ${MSK_BOOTSTRAP_SERVERS}

logging:
  level:
    root: WARN
    com.intelliflow: INFO
